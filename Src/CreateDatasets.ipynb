{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3108bea0",
   "metadata": {},
   "source": [
    "# Dataset creation from API notebook\n",
    "The purpose of this notebook is to use the Pageviews API  \n",
    "from https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews  \n",
    "to create three datasets of url traffic data from July 2015 through the previous complete month.  \n",
    "The pages that will be considered for these datasets are located in /Data/ArticleNames.csv.  \n",
    "\n",
    "The three datasets are described to be:  \n",
    "```\n",
    "Dataset1: Get all monthly mobile pageviews per article\n",
    "Dataset2: Get all monthly desktop pageviews per article\n",
    "Dataset3: Get all monthly desktop+mobile pageviews per article\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6419712",
   "metadata": {},
   "source": [
    "# Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d852fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e66ced",
   "metadata": {},
   "source": [
    "# Load in article data that we want to process into list of lists\n",
    "#### Step 1: First, we want to open the comma-separated file that is of the format: Title,URL .\n",
    "#### Step 2: Next, we will loop through csv file and load data into a list.\n",
    "#### Step 3: After that, we will remove the header row from list to prevent it showing up later.\n",
    "#### Step 4: Finally, we will fonfirm data was properly loaded by printing out the first few results and the total number of articles read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381c126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Everything Everywhere All at Once', 'https://en.wikipedia.org/wiki/Everything_Everywhere_All_at_Once']\n",
      "['All Quiet on the Western Front (2022 film)', 'https://en.wikipedia.org/wiki/All_Quiet_on_the_Western_Front_(2022_film)']\n",
      "['The Whale (2022 film)', 'https://en.wikipedia.org/wiki/The_Whale_(2022_film)']\n",
      "Number of articles, should be 1359: 1359\n"
     ]
    }
   ],
   "source": [
    "#Step1: Open csv file that is of the format: Title, URL \n",
    "ArticleInfo = []\n",
    "with open('../Data/ArticleNames.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    #Step 2: Loop through csv file and load data into a list  \n",
    "    for row in reader: ArticleInfo.append([row[0], row[1]]) \n",
    "\n",
    "#Step 3: Remove header row from list to prevent it showing up later\n",
    "ArticleInfo.pop(0)\n",
    "\n",
    "#Step 4: Confirm data was loading by printing out the first few results and the total number of articles read in\n",
    "for i in range(3): print(ArticleInfo[i])\n",
    "print(\"Number of articles, should be 1359:\", len(ArticleInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e789df01",
   "metadata": {},
   "source": [
    "# Helper functions and variables for using the Pageviews API\n",
    "\n",
    "The code in this cell was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 14, 2023. Some of the original code made be modified, however it still falls under the Creative Commons license.\n",
    "\n",
    "#### The code below simply defines a handful of constants used for requesting data from pageviews API, there are no specific steps here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36faf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are CONSTANTS used by the API that are relevant to all subsequent API calls\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<zbowyer@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "def request_pageviews_per_article(article_title = None, endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "    '''\n",
    "    Description:\n",
    "        Used to request data for a single article, uses defined constants above for params\n",
    "    Input(s):\n",
    "        article_title - String\n",
    "        endpoint_url - String\n",
    "        endpoint_params - String\n",
    "        request_template - Dictionary\n",
    "        headers - Dictionary\n",
    "    Outputs:\n",
    "        json_response - JSON string/object\n",
    "    '''\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    title_replaced = request_template['article'].replace(' ','_')\n",
    "    article_title_encoded = urllib.parse.quote(title_replaced)\n",
    "    request_template['article'] = article_title_encoded\n",
    "    article_title_encoded = (article_title_encoded.replace('/', '%2F'))\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    #print(request_url)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90038148",
   "metadata": {},
   "source": [
    "## Create first dataset: Get all monthly mobile pageviews per article\n",
    "#### Step 1: We want to define the json request objects used to retreive data in an abstract manner for both forms of mobile data.\n",
    "#### Step 2: Then we will loop over each article name that we stored earlier and store the total mobile views for each monthin a dictionary. \n",
    "#### Step 3: Next, we will sort that dictionary alphabetically by the name of the article in a descending fashion.\n",
    "#### Step 4: Finally, we will save the dictionary as a javascript object notation file.\n",
    "\n",
    "File will be named: academy_monthly_mobile_201501-202309.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f808df0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for ['Victor/Victoria', 'https://en.wikipedia.org/wiki/Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Define the json request objects used to retreive data in an abstract manner for both forms of mobile data.\n",
    "ARTICLE_PAGEVIEWS_MOBILE_app = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"mobile-app\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023100100\"    # this is likely the wrong end date\n",
    "}\n",
    "ARTICLE_PAGEVIEWS_MOBILE_web = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"mobile-web\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023100100\"    # this is likely the wrong end date\n",
    "}\n",
    "\n",
    "#Step 2: Loop over each article name that we stored earlier and store the total mobile views for each monthin a dictionary. \n",
    "results = {}\n",
    "for article in ArticleInfo:\n",
    "    #Get mobile app and mobile web views\n",
    "    request1 = request_pageviews_per_article(article[0], request_template=ARTICLE_PAGEVIEWS_MOBILE_app)\n",
    "    request2 = request_pageviews_per_article(article[0], request_template=ARTICLE_PAGEVIEWS_MOBILE_web)\n",
    "    \n",
    "    #Store combined views for each month\n",
    "    inner_dictionary = {\"Views\": {}}\n",
    "    if(request1.__contains__(\"items\") and request2.__contains__(\"items\")):\n",
    "        for i in range(len(request1['items'])):\n",
    "            month = request1['items'][i]['timestamp']\n",
    "            views = request1['items'][i]['views'] + request2['items'][i]['views']\n",
    "            inner_dictionary[\"Views\"][month] = views\n",
    "    elif(request2.__contains__(\"items\")):\n",
    "        for i in range(len(request1['items'])):\n",
    "            month = request2['items'][i]['timestamp']\n",
    "            views = request2['items'][i]['views'] \n",
    "            inner_dictionary[\"Views\"][month] = views\n",
    "    elif(request1.__contains__(\"items\")):\n",
    "         for i in range(len(request1['items'])):\n",
    "            month = request1['items'][i]['timestamp']\n",
    "            views = request1['items'][i]['views'] \n",
    "            inner_dictionary[\"Views\"][month] = views\n",
    "    else:\n",
    "        print(\"Missing data for\", article)\n",
    "        continue\n",
    "    \n",
    "    #Add to final dictionary\n",
    "    results[article[0]] = inner_dictionary\n",
    "\n",
    "#Step 3: Sort dictionary alphabetically by the name of the article in a descending fashion\n",
    "results = sorted(results.items(), key=lambda x:x[0])\n",
    "\n",
    "#Step 4: Write to file\n",
    "with open(\"../Data/academy_monthly_mobile_201501-202309.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c7094",
   "metadata": {},
   "source": [
    "## Create Dataset2: Get all monthly desktop pageviews per article\n",
    "#### Step 1: We want to define the json request object used to retreive data in an abstract manner for desktop data.\n",
    "#### Step 2: Then we will loop over each article name that we stored earlier and store the total desktop views for each month in a dictionary. \n",
    "#### Step 3: Next, we will sort that dictionary alphabetically by the name of the article in a descending fashion.\n",
    "#### Step 4: Finally, we will save the dictionary as a javascript object notation file.\n",
    "\n",
    "File will be named: academy_monthly_desktop_201501-202309.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00532fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for ['Victor/Victoria', 'https://en.wikipedia.org/wiki/Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Define the json request objects used to retreive data in an abstract manner for dekstop data.\n",
    "ARTICLE_PAGEVIEWS_desktop = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"desktop\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023100100\"    # this is likely the wrong end date\n",
    "}\n",
    "\n",
    "#Step 2: Loop over each article name that we stored earlier and store the total desktop views for each monthin a dictionary. \n",
    "results = {}\n",
    "for article in ArticleInfo:\n",
    "    #Get desktop view data\n",
    "    request1 = request_pageviews_per_article(article[0], request_template=ARTICLE_PAGEVIEWS_desktop)\n",
    "    \n",
    "    if(request1.__contains__(\"items\")):\n",
    "        #Store combined views for each month\n",
    "        inner_dictionary = {\"Views\": {}}\n",
    "        for i in range(len(request1['items'])):\n",
    "            month = request1['items'][i]['timestamp']\n",
    "            views = request1['items'][i]['views']\n",
    "            inner_dictionary[\"Views\"][month] = views\n",
    "    else:\n",
    "        print(\"Missing data for\", article)\n",
    "        continue\n",
    "    \n",
    "    #Add to final dictionary\n",
    "    results[article[0]] = inner_dictionary\n",
    "\n",
    "#Step 3: Sort dictionary alphabetically by the name of the article in a descending fashion\n",
    "results = sorted(results.items(), key=lambda x:x[0])\n",
    "\n",
    "#Step 4: Save the dictionary as a javascript object notation file\n",
    "with open(\"../Data/academy_monthly_desktop_201501-202309.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f7780",
   "metadata": {},
   "source": [
    "## Create Dataset3: Get all monthly desktop+mobile pageviews per article\n",
    "#### Step 1: We want to define the json request object used to retreive data in an abstract manner for all data.\n",
    "#### Step 2: Then we will loop over each article name that we stored earlier and store the total all views for each month in a dictionary. \n",
    "#### Step 3: Next, we will sort that dictionary alphabetically by the name of the article in a descending fashion.\n",
    "#### Step 4: Finally, we will save the dictionary as a javascript object notation file.\n",
    "\n",
    "File will be named: academy_monthly_cumulative_201501-202309.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6347663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for ['Victor/Victoria', 'https://en.wikipedia.org/wiki/Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Define the json request objects used to retreive data in an abstract manner for all data.\n",
    "ARTICLE_PAGEVIEWS_all = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"all-access\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023100100\"    # this is likely the wrong end date\n",
    "}\n",
    "\n",
    "#Step 2: Loop over each article name that we stored earlier and store the total cumulative views for each monthin a dictionary. \n",
    "results = {}\n",
    "for article in ArticleInfo:\n",
    "    #Get cumulative view data\n",
    "    request1 = request_pageviews_per_article(article[0], request_template=ARTICLE_PAGEVIEWS_all)\n",
    "  \n",
    "    if(request1.__contains__(\"items\")):\n",
    "        #Store combined views for each month\n",
    "        inner_dictionary = {\"Views\": {}}\n",
    "        for i in range(len(request1['items'])):\n",
    "            month = request1['items'][i]['timestamp']\n",
    "            views = request1['items'][i]['views']\n",
    "            inner_dictionary[\"Views\"][month] = views\n",
    "    else:\n",
    "        print(\"Missing data for\", article)\n",
    "        continue\n",
    "    \n",
    "    #Add to final dictionary\n",
    "    results[article[0]] = inner_dictionary\n",
    "\n",
    "#Step 3: Sort dictionary alphabetically by the name of the article in a descending fashion\n",
    "results = sorted(results.items(), key=lambda x:x[0])\n",
    "\n",
    "#Step 4: Save the dictionary as a javascript object notation file\n",
    "with open(\"../Data/academy_monthly_cumulative_201501-202309.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb27e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
